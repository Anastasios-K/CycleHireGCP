{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc483196-18ec-4b3f-ba01-963e58ff0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import shape, Point\n",
    "from google.cloud import bigquery\n",
    "from ..helper.helper import Printer\n",
    "from ..model_development.s3_explore_data import DataExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a69fc7-4d8c-4f19-bc76-265093e2f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Access the cycle_stations table from the London Bicycle Hires data in GCP and process it.\n",
    "        1. Load the Geo-spatial data of London boroughs.\n",
    "           This is an external source. \n",
    "           The data is stored in a json file and located in London_geodata directory (in the root directory).\n",
    "        2. Load the cycle_stations data.\n",
    "        3. Iterate through the cycle_stations data and use a function to identify in which London borough each cycle station is located.\n",
    "        4. Save the data in pd dataframe format in the info_tracker object.\n",
    "        5. Store the processed data in a bigquery dataset.\n",
    "        6. Create preview for the processed data.\n",
    "\n",
    "    :param config: An object that reads the pipeline configurations from a yaml file and load them. Initiated at the beginning of the pipeline.              \n",
    "    :param info_tracker: An object that is used throughout the pipeline to track useful information. Initiated at the beginning of the pipeline.\n",
    "    :param gcp_client: A Google Cloud Platform client. Initiated at the beginning of the pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, info_tracker, gcp_client):\n",
    "        self.config = config\n",
    "        self.info_tracker = info_tracker\n",
    "        self.__gcp_client = gcp_client\n",
    "\n",
    "        self.__london_geodf = self.__load_London_geodata()\n",
    "        self.__bike_stations_data = self.__load_stations_data()\n",
    "        self.info_tracker.cycle_station_data_with_borough_names = self.__add_borough_name_in_station_data()\n",
    "        self.__upload_cycle_station_data_with_borough_names_to_bigquery()\n",
    "        self.info_tracker.cycle_station_with_borough_names_preview = self.__create_cycle_station_data_with_borough_names_preview()\n",
    "\n",
    "    def __load_London_geodata(self) -> gpd.GeoDataFrame:\n",
    "        \"\"\" Load the London Geo data. \"\"\"\n",
    "\n",
    "        # Make geojson path and read London geo-data\n",
    "        geojson_path = os.path.join(self.config.paths.london_geodata_dir, self.config.paths.london_geodata_file)\n",
    "        london_geodf = gpd.read_file(geojson_path)\n",
    "        \n",
    "        # print(london_geodf)\n",
    "        return london_geodf\n",
    "\n",
    "    def __load_stations_data(self) -> pd.DataFrame:\n",
    "        \"\"\" Load the cycle_stations data from GCP. \"\"\"\n",
    "\n",
    "        # Build query\n",
    "        query_job = self.__gcp_client.query(\n",
    "            f\"\"\" \n",
    "            SELECT *\n",
    "            FROM bigquery-public-data.london_bicycles.{self.config.database.station_table}\n",
    "            \"\"\"\n",
    "        )\n",
    "        # Call query and extract data in pandas df\n",
    "        df = query_job.result().to_dataframe()\n",
    "        \n",
    "        # print(df)\n",
    "        return df\n",
    "\n",
    "    def __identify_london_brough(self, given_lat: float, given_lon: float) -> str:\n",
    "        \"\"\" \n",
    "        Take latitude and longitude of a specific cycle station.\n",
    "        Create a geo-point.\n",
    "        Iterates through the London boroughs geo-boundaries to identify the borough where the geometric point is located.\n",
    "        Return the borough name\n",
    "        \"\"\"\n",
    "\n",
    "        # Make a geo-point using the given latitude and longitude\n",
    "        point = Point(given_lon, given_lat)\n",
    "\n",
    "        # Init a borough name\n",
    "        borough_name = \"no_borough\"\n",
    "\n",
    "        # Iterate through London boroughs geo-data and design a polygon based on the spatial boundaries\n",
    "        for idx in range(len(self.__london_geodf)):\n",
    "            polygon = shape(self.__london_geodf.loc[idx, \"geometry\"])\n",
    "\n",
    "            # Check if the polygon contains the created geo-point\n",
    "            if polygon.contains(point):\n",
    "                borough_name = self.__london_geodf.loc[idx, \"name\"]\n",
    "        \n",
    "        return borough_name\n",
    "                \n",
    "    def __add_borough_name_in_station_data(self):\n",
    "        \"\"\" \n",
    "        Use the function identify_london_borough to identify the borough name for each given combination of lat and lon.\n",
    "        Iterate through the cycle_stations table to identify the corresponding borough of each bike station.\n",
    "        Add the borough name in a new column called borough_name.\n",
    "        \"\"\"\n",
    "\n",
    "        # Copy the cycle_station df to make an indipendent local variable\n",
    "        local_df = self.__bike_stations_data.copy()\n",
    "        \n",
    "        # Make a new column called borough name and fill it with the string borough_name.\n",
    "        local_df[\"borough_name\"] = \"name\"\n",
    "\n",
    "        # Iterate through the station data and extract the latitude and longitude of each station\n",
    "        for row in range(len(local_df)):\n",
    "            lat = local_df.loc[row, \"latitude\"]\n",
    "            lon = local_df.loc[row, \"longitude\"]\n",
    "\n",
    "            # Use the identify_london_brough method to identify the corresponding borough for the given cycle station\n",
    "            borough_name = self.__identify_london_brough(given_lat=lat, given_lon=lon)\n",
    "\n",
    "            # Add the borough name in the same row, in the borough name column\n",
    "            local_df.loc[row, \"borough_name\"] = borough_name\n",
    "        \n",
    "        # print(local_df)\n",
    "        return local_df\n",
    "\n",
    "    def __upload_cycle_station_data_with_borough_names_to_bigquery(self):\n",
    "        \"\"\" Load the crated cycle station data with borough names to bigquery. \"\"\"\n",
    "\n",
    "        # Set a name to temporarily save the processed cycle station data\n",
    "        file_name = \"temp_df.csv\"\n",
    "\n",
    "        # Access the processed data from the info tracker object\n",
    "        temp_df = self.info_tracker.cycle_station_data_with_borough_names\n",
    "\n",
    "        # Save the data locally\n",
    "        temp_df.to_csv(file_name)\n",
    "\n",
    "        # Set the configurations of the uploading bigquery job\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            source_format=bigquery.SourceFormat.CSV,\n",
    "            # skip_leading_rows=1,\n",
    "            autodetect=True\n",
    "        )\n",
    "\n",
    "        # Set the table id, including the project and the dataset ids\n",
    "        table_id = f\"{self.config.database.my_project}.{self.config.database.my_dataset}.{self.config.database.my_table}\"\n",
    "\n",
    "        # Run the bigquery uploading job\n",
    "        with open(rf\"{file_name}\", \"rb\") as source_file:\n",
    "            job = self.__gcp_client.load_table_from_file(source_file, table_id, job_config=job_config)\n",
    "\n",
    "        while job.state != \"DONE\":\n",
    "            time.sleep(10)\n",
    "            job.reload()\n",
    "            print(job.state)\n",
    "\n",
    "        # Delete temporary df\n",
    "        os.remove(file_name)\n",
    "\n",
    "    def __create_cycle_station_data_with_borough_names_preview(self) -> pd.DataFrame:\n",
    "        \"\"\" Create a preview of the cycle_station_data_with_borough_names table. The data is limited to 100 rows to accelerate the process. \"\"\"\n",
    "\n",
    "        # Define a name to be used in the Printer class\n",
    "        name = \"Cycle_station_with_borough_names_preview\"\n",
    "        \n",
    "        # Build query\n",
    "        query_job = self.__gcp_client.query(\n",
    "            f\"\"\" \n",
    "            SELECT *\n",
    "            FROM {self.config.database.my_project}.{self.config.database.my_dataset}.{self.config.database.my_table}\n",
    "            LIMIT 100\n",
    "            \"\"\"\n",
    "        )\n",
    "        # Call query and extract data in pandas df\n",
    "        df = query_job.result().to_dataframe()\n",
    "\n",
    "        # Print outcome if show config is True\n",
    "        if self.config.show_outcome.show_outcome:\n",
    "            Printer().print_outcome(outcome=df, display_name=name)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    def explore_data(self):\n",
    "        return DataExplorer(\n",
    "            config=self.config,\n",
    "            info_tracker=self.info_tracker,\n",
    "            gcp_client=self.__gcp_client\n",
    "        )\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
